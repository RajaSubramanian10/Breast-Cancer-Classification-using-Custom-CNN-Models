{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RajaSubramanian10/Breast-Cancer-Classification-using-Custom-CNN-Models/blob/main/BreastCancerClassification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "id": "lleuDiuM75F1"
      },
      "source": [
        "***Deep Learning based classifier for Breast Cancer Images***\n",
        "\n",
        "**Author - Prof. R. Raja Subramanian**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bOO7ACKiR1-W",
        "outputId": "c35da59c-de24-44a1-b7ca-9aaa18e24fa9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.10/dist-packages (4.8.0.76)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from opencv-python) (1.23.5)\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement tensorflow==2.6.0 (from versions: 2.8.0rc0, 2.8.0rc1, 2.8.0, 2.8.1, 2.8.2, 2.8.3, 2.8.4, 2.9.0rc0, 2.9.0rc1, 2.9.0rc2, 2.9.0, 2.9.1, 2.9.2, 2.9.3, 2.10.0rc0, 2.10.0rc1, 2.10.0rc2, 2.10.0rc3, 2.10.0, 2.10.1, 2.11.0rc0, 2.11.0rc1, 2.11.0rc2, 2.11.0, 2.11.1, 2.12.0rc0, 2.12.0rc1, 2.12.0, 2.12.1, 2.13.0rc0, 2.13.0rc1, 2.13.0rc2, 2.13.0, 2.13.1, 2.14.0rc0, 2.14.0rc1, 2.14.0, 2.14.1, 2.15.0rc0, 2.15.0rc1, 2.15.0, 2.15.0.post1)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for tensorflow==2.6.0\u001b[0m\u001b[31m\n",
            "\u001b[0mRequirement already satisfied: tensorflow in /usr/local/lib/python3.10/dist-packages (2.14.0)\n",
            "Collecting tensorflow\n",
            "  Downloading tensorflow-2.15.0.post1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (475.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m475.2/475.2 MB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=23.5.26 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.5.26)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.5.4)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.9.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (16.0.6)\n",
            "Requirement already satisfied: ml-dtypes~=0.2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.23.5)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow) (23.2)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (2.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (4.5.0)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (0.34.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow) (1.59.3)\n",
            "Collecting tensorboard<2.16,>=2.15 (from tensorflow)\n",
            "  Downloading tensorboard-2.15.1-py3-none-any.whl (5.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m49.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow-estimator<2.16,>=2.15.0 (from tensorflow)\n",
            "  Downloading tensorflow_estimator-2.15.0-py2.py3-none-any.whl (441 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m442.0/442.0 kB\u001b[0m \u001b[31m33.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting keras<2.16,>=2.15.0 (from tensorflow)\n",
            "  Downloading keras-2.15.0-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m46.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow) (0.42.0)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.5.1)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (2.31.0)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.16,>=2.15->tensorflow) (3.0.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (5.3.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (1.3.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow) (2023.11.17)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow) (0.5.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow) (3.2.2)\n",
            "Installing collected packages: tensorflow-estimator, keras, tensorboard, tensorflow\n",
            "\u001b[33m  WARNING: The script tensorboard is installed in '/root/.local/bin' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33m  WARNING: The scripts estimator_ckpt_converter, import_pb_to_tensorboard, saved_model_cli, tensorboard, tf_upgrade_v2, tflite_convert, toco and toco_from_protos are installed in '/root/.local/bin' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
            "\u001b[0mSuccessfully installed keras-2.15.0 tensorboard-2.15.1 tensorflow-2.15.0.post1 tensorflow-estimator-2.15.0\n",
            "Requirement already satisfied: pip in /usr/local/lib/python3.10/dist-packages (23.1.2)\n",
            "Collecting pip\n",
            "  Downloading pip-23.3.1-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pip\n",
            "\u001b[33m  WARNING: The scripts pip, pip3 and pip3.10 are installed in '/root/.local/bin' which is not on PATH.\n",
            "  Consider adding this directory to PATH or, if you prefer to suppress this warning, use --no-warn-script-location.\u001b[0m\u001b[33m\n",
            "\u001b[0mSuccessfully installed pip-23.3.1\n"
          ]
        }
      ],
      "source": [
        "!pip install opencv-python\n",
        "!pip install tensorflow==2.6.0\n",
        "!pip install tensorflow --upgrade --user\n",
        "!pip install pip --upgrade --user\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "SejSo2c475F2"
      },
      "outputs": [],
      "source": [
        "#importing libraries\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers,models\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "import os\n",
        "import PIL\n",
        "import numpy as np\n",
        "import pathlib\n",
        "import glob"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cRU0uBofZsIa"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OMDrDCe_cI0D"
      },
      "outputs": [],
      "source": [
        "#assigning directory\n",
        "directory=pathlib.Path(\"/content/drive/My Drive/BreaKHis 400X/BreaKHis 400X/train\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E7Xar4dSX-rO"
      },
      "outputs": [],
      "source": [
        "# Just needed in case you'd like to append it to an array\n",
        "data = []\n",
        "\n",
        "for filename in os.listdir(\".\"):\n",
        "    if filename.endswith(\"png\"):\n",
        "        # Your code comes here such as\n",
        "        print(filename)\n",
        "        data.append(filename)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RMuPDJl775F4"
      },
      "outputs": [],
      "source": [
        "#count of images in the directory given\n",
        "image_count=len(list(directory.glob('*/*.png')))\n",
        "#print(list(directory.glob('/*.jpg')))\n",
        "image_count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3T-9YLUf75F4"
      },
      "outputs": [],
      "source": [
        "#creating dictionary of flower species\n",
        "flower_images_dict={\n",
        "    \"benign\":list(directory.glob('benign/*.png')),\n",
        "    \"malignant\":list(directory.glob('malignant/*.png'))\n",
        "\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8hIYz1Qk75F5"
      },
      "outputs": [],
      "source": [
        "flower_images_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JRSaMtzw75F5"
      },
      "outputs": [],
      "source": [
        "#Different species list\n",
        "keys=[\"benign\",\"malignant\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nd2CHyRs75F5"
      },
      "outputs": [],
      "source": [
        "#resizing and creating labels using computer vision\n",
        "resized,labels=[],[]\n",
        "for flower_name,images in flower_images_dict.items():\n",
        "    for image in images:\n",
        "        print(\"completed\")\n",
        "        img=cv2.imread(str(image))\n",
        "        resized_image=cv2.resize(img,(224,224))\n",
        "        resized.append(resized_image)\n",
        "        labels.append(keys.index(flower_name))\n",
        "flower_images_dict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zPBxcxuZ75F6"
      },
      "outputs": [],
      "source": [
        "#function to print images\n",
        "def print_image(i,j):\n",
        "    plt.imshow(i)\n",
        "    plt.title(keys[j])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xYknOTgC75F6"
      },
      "outputs": [],
      "source": [
        "#splitting data into train and test\n",
        "#if any integer is given to random_state it will generate and give same set of data each time we run the code and if we give\n",
        "#None different sequences will be generated\n",
        "from sklearn.model_selection import train_test_split\n",
        "x_train,x_test,y_train,y_test=train_test_split(resized,labels,test_size=0.25,random_state=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b4KuqDaU75F6"
      },
      "outputs": [],
      "source": [
        "print_image(x_train[15],y_train[15])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_0AG6lnE75F6"
      },
      "outputs": [],
      "source": [
        "print_image(x_test[6],y_test[6])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J4Dl2oWK75F7"
      },
      "outputs": [],
      "source": [
        "#normalizing data\n",
        "x_train_scaled=np.array(x_train)/255\n",
        "x_test_scaled=np.array(x_test)/255"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cggoRc9N75F7"
      },
      "outputs": [],
      "source": [
        "x_train_scaled.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LiE2vKEe75F7"
      },
      "outputs": [],
      "source": [
        "y_train=np.array(y_train)\n",
        "y_train.shape"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "id": "ICZhPT9z75F8"
      },
      "source": [
        "#Simple CNN Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wh6tmoYG75F8"
      },
      "outputs": [],
      "source": [
        "model=models.Sequential([\n",
        "    layers.Conv2D(16,3,padding='same',activation='relu'),\n",
        "    layers.MaxPooling2D(),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(128,activation=\"relu\"),\n",
        "    layers.Dense(2,activation=\"softmax\")])\n",
        "model.compile(\n",
        "optimizer=\"adam\",loss=\"sparse_categorical_crossentropy\",metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9y3zn-Y775F8"
      },
      "outputs": [],
      "source": [
        "model.fit(x_train_scaled,np.array(y_train),epochs=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qrMxlm3n75F8"
      },
      "outputs": [],
      "source": [
        "model.evaluate(x_test_scaled,np.array(y_test))"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "id": "Kehfl33-75F9"
      },
      "source": [
        "#CNN Model With Data Augumentation layers and Dropout layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0lzZ5t7c75F9"
      },
      "outputs": [],
      "source": [
        "model1=models.Sequential([\n",
        "    layers.experimental.preprocessing.RandomZoom(0.3),\n",
        "    layers.Conv2D(16,3,padding='same',activation='relu'),\n",
        "    layers.MaxPooling2D(),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(128,activation=\"relu\"),\n",
        "    layers.Dropout(0.3),\n",
        "    layers.Dense(64,activation=\"relu\"),\n",
        "    layers.Dropout(0.3),\n",
        "    layers.Dense(2,activation=\"softmax\")\n",
        "    #layers.Dense(2,kernel_regularizer=l2(0.01),activation=\"softmax\")\n",
        "])\n",
        "model1.compile(\n",
        "optimizer=\"adam\",loss=\"sparse_categorical_crossentropy\",metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SjBeLswr75F9"
      },
      "outputs": [],
      "source": [
        "model1.fit(x_train_scaled,np.array(y_train),epochs=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Oal8ghtE75F-"
      },
      "outputs": [],
      "source": [
        "model1.evaluate(x_test_scaled,np.array(y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#CNN Model with only Dropout layers"
      ],
      "metadata": {
        "id": "p90hBJlOA0r5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KFPaMHHc75F_"
      },
      "outputs": [],
      "source": [
        "model2=models.Sequential([\n",
        "    layers.MaxPooling2D(),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(128,activation=\"relu\"),\n",
        "    layers.Dropout(0.3),\n",
        "    layers.Dense(64,activation=\"relu\"),\n",
        "    layers.Dropout(0.3),\n",
        "    layers.Dense(2,activation=\"softmax\")\n",
        "])\n",
        "model2.compile(\n",
        "optimizer=\"adam\",loss=\"sparse_categorical_crossentropy\",metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "--5DLRjR75F_"
      },
      "outputs": [],
      "source": [
        "model2.fit(x_train_scaled,np.array(y_train),epochs=15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ju0ukXQZ75F_"
      },
      "outputs": [],
      "source": [
        "model2.evaluate(x_test_scaled,np.array(y_test))"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "id": "8agljnqs75F_"
      },
      "source": [
        "#CNN Model only with Augumentation layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SwRjvyP-75F_"
      },
      "outputs": [],
      "source": [
        "model3=models.Sequential([\n",
        "    layers.experimental.preprocessing.RandomZoom(0.3),\n",
        "    layers.Conv2D(16,3,padding='same',activation='relu'),\n",
        "    layers.MaxPooling2D(),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(128,activation=\"relu\"),\n",
        "    layers.Dropout(0.3),\n",
        "    layers.Dense(64,activation=\"relu\"),\n",
        "    layers.Dense(32,activation=\"relu\"),\n",
        "    layers.Dense(2,activation=\"softmax\")\n",
        "])\n",
        "model3.compile(\n",
        "optimizer=\"adam\",loss=\"sparse_categorical_crossentropy\",metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mpN1JZy775GA"
      },
      "outputs": [],
      "source": [
        "model3.fit(x_train_scaled,np.array(y_train),epochs=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ycZBCdJ075GA"
      },
      "outputs": [],
      "source": [
        "model3.evaluate(x_test_scaled,np.array(y_test))"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "id": "Xv6j8GYe75GA"
      },
      "source": [
        "#CNN Model with two different augumentation layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BYUCVwAb75GA"
      },
      "outputs": [],
      "source": [
        "model4=models.Sequential([\n",
        "    layers.experimental.preprocessing.RandomZoom(0.3),\n",
        "    layers.experimental.preprocessing.RandomFlip(mode=\"horizontal_and_vertical\"),\n",
        "    layers.Conv2D(16,3,padding='same',activation='relu'),\n",
        "    layers.MaxPooling2D(),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(128,activation=\"relu\"),\n",
        "    layers.Dense(2,activation=\"softmax\")\n",
        "])\n",
        "model4.compile(\n",
        "optimizer=\"adam\",loss=\"sparse_categorical_crossentropy\",metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "akpoOG_V75GA"
      },
      "outputs": [],
      "source": [
        "model4.fit(x_train_scaled,np.array(y_train),epochs=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dVjv0t4d75GA"
      },
      "outputs": [],
      "source": [
        "model4.evaluate(x_test_scaled,np.array(y_test))"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "id": "lQhHPEJV75GB"
      },
      "source": [
        "#CNN Model with Data Augumentation layer and more dense layers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kdgD2RT675GB"
      },
      "outputs": [],
      "source": [
        "model5=models.Sequential([\n",
        "    layers.experimental.preprocessing.RandomZoom(0.3),\n",
        "    layers.Conv2D(16,3,padding='same',activation='relu'),\n",
        "    layers.MaxPooling2D(),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(128,activation=\"relu\"),\n",
        "    layers.Dense(64,activation=\"relu\"),\n",
        "    layers.Dense(32,activation=\"relu\"),\n",
        "    layers.Dense(2,activation=\"softmax\")\n",
        "])\n",
        "model5.compile(\n",
        "optimizer=\"adam\",loss=\"sparse_categorical_crossentropy\",metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MM4tbyrW75GB"
      },
      "outputs": [],
      "source": [
        "model5.fit(x_train_scaled,np.array(y_train),epochs=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-_8C3wuB75GB"
      },
      "outputs": [],
      "source": [
        "model5.evaluate(x_test_scaled,np.array(y_test))"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "id": "i9voOkyU75GB"
      },
      "source": [
        "#CNN MODEL THAT USES FILTERS IN ALL THE LAYERS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wo2JcFll75GC"
      },
      "outputs": [],
      "source": [
        "myCNN=tf.keras.models.Sequential([\n",
        "    layers.BatchNormalization(),\n",
        "    layers.Conv2D(32,3,activation=\"relu\"),\n",
        "    layers.MaxPooling2D(),\n",
        "    layers.Conv2D(64,3,activation=\"relu\"),\n",
        "    layers.MaxPooling2D(),\n",
        "    layers.Conv2D(128,3,activation=\"relu\"),\n",
        "    layers.MaxPooling2D(),\n",
        "    layers.Flatten(),\n",
        "    layers.Dense(256,activation=\"relu\"),\n",
        "    layers.Dense(2,activation=\"softmax\")\n",
        "])\n",
        "myCNN.compile(optimizer=\"adam\",loss=\"sparse_categorical_crossentropy\",metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gUKvtsx275GC"
      },
      "outputs": [],
      "source": [
        "myCNN.fit(x_train_scaled,np.array(y_train),epochs=5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5QZKW_p675GC"
      },
      "outputs": [],
      "source": [
        "myCNN.evaluate(x_test_scaled,np.array(y_test))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}